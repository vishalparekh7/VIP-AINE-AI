{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Virtual Internship Program by AINE AI__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Project : Classifying Covid-19 Positive and Negative Patients from X-Ray Images__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Aim: With the Chest X - Ray dataset, develop a Deep Learning Model to classify the X Rays of Healthy vs Corona Positive Patients__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####    -: __Vishal Parekh__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = ['Covid Negative', 'Covid Positive'] #Name of the Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = r'Dataset' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [i for i in range(len(CATEGORIES))]\n",
    "label_dict = dict(zip(CATEGORIES, labels)) #Creating dictionary for labels by merging two list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "{'Covid Negative': 0, 'Covid Positive': 1}\n"
     ]
    }
   ],
   "source": [
    "print(labels)\n",
    "print(label_dict) # 0 for Negative and 1 for positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing and Converting to Gray Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 64\n",
    "data = []\n",
    "target = []\n",
    "\n",
    "for category in CATEGORIES: #iterating through each folders\n",
    "    path = os.path.join(DIRECTORY, category) #Path of the dataset i.e joining the path\n",
    "    img_names = os.listdir(path)\n",
    "    \n",
    "    for img_name in img_names: # iterate through each image\n",
    "        img_path = os.path.join(path, img_name)\n",
    "        img = cv.imread(img_path) #reading each image files\n",
    "        \n",
    "        try:\n",
    "            gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY) #Converting the image into gray scale\n",
    "            resize = cv.resize(gray,(img_size, img_size))#resizing the image for all\n",
    "            data.append(resize) #appending the data/features to the empty data list\n",
    "            target.append(label_dict[category]) #appending the target labels into the empty target list\n",
    "            #appending the image and the label into the list\n",
    "        except Exception as e:\n",
    "            print(\"Exception: \",e)\n",
    "            #Exception for image corruption or unavailable and continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data) / 255.0 #Converting to numpy array and normalize the data to 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2513, 64, 64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape #2271 images of size 100X100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = target.copy() #target containing the labels of the image i.e 0,1 for negative and normal images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(x, open('x.pkl','wb')) #save the processed variable to our local machine\n",
    "pickle.dump(y, open('y.pkl','wb')) #wb is write binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = pickle.load(open('x.pkl', 'rb')) #loading the pickle files\n",
    "y = pickle.load(open('y.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(-1, 64, 64, 1) # for CNN model we need to reshape it to 4D array (batchsize,height,width and depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2513, 64, 64, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.layers import Conv2D,Activation,MaxPooling2D\n",
    "from keras.utils import normalize\n",
    "from keras import Input\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape = X.shape[1:])) #In CNN. input shpae has to be given in the first layer\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2))) \n",
    "model.add(Conv2D(32, (3, 3))) #2nd CNN layer with 32 filter with 3,3\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Flatten()) # Converting to 1D matrix\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(128)) #128 neurons in the hidden layers\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation = 'softmax')) #Final layers of 2 layers same as the output to predict\n",
    "model.compile(optimizer = 'adam', loss = \"sparse_categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 64)        640       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 29, 29, 32)        18464     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 29, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 846,946\n",
      "Trainable params: 846,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "64/64 [==============================] - 11s 152ms/step - loss: 0.6490 - accuracy: 0.5760 - val_loss: 0.2972 - val_accuracy: 0.9471\n",
      "Epoch 2/20\n",
      "64/64 [==============================] - 9s 134ms/step - loss: 0.2317 - accuracy: 0.9318 - val_loss: 0.1680 - val_accuracy: 0.9295\n",
      "Epoch 3/20\n",
      "64/64 [==============================] - 9s 134ms/step - loss: 0.1302 - accuracy: 0.9594 - val_loss: 0.0833 - val_accuracy: 0.9648\n",
      "Epoch 4/20\n",
      "64/64 [==============================] - 9s 137ms/step - loss: 0.1108 - accuracy: 0.9674 - val_loss: 0.0718 - val_accuracy: 0.9956\n",
      "Epoch 5/20\n",
      "64/64 [==============================] - 9s 139ms/step - loss: 0.0737 - accuracy: 0.9741 - val_loss: 0.0429 - val_accuracy: 0.9912\n",
      "Epoch 6/20\n",
      "64/64 [==============================] - 8s 132ms/step - loss: 0.0701 - accuracy: 0.9710 - val_loss: 0.0541 - val_accuracy: 0.9780\n",
      "Epoch 7/20\n",
      "64/64 [==============================] - 8s 132ms/step - loss: 0.0614 - accuracy: 0.9768 - val_loss: 0.0557 - val_accuracy: 0.9868\n",
      "Epoch 8/20\n",
      "64/64 [==============================] - 9s 139ms/step - loss: 0.0612 - accuracy: 0.9793 - val_loss: 0.0436 - val_accuracy: 0.9780\n",
      "Epoch 9/20\n",
      "64/64 [==============================] - 9s 136ms/step - loss: 0.0512 - accuracy: 0.9837 - val_loss: 0.0323 - val_accuracy: 0.9912\n",
      "Epoch 10/20\n",
      "64/64 [==============================] - 9s 138ms/step - loss: 0.0515 - accuracy: 0.9803 - val_loss: 0.0213 - val_accuracy: 0.9956\n",
      "Epoch 11/20\n",
      "64/64 [==============================] - 9s 142ms/step - loss: 0.0495 - accuracy: 0.9793 - val_loss: 0.1433 - val_accuracy: 0.9604\n",
      "Epoch 12/20\n",
      "64/64 [==============================] - 9s 134ms/step - loss: 0.0817 - accuracy: 0.9776 - val_loss: 0.0263 - val_accuracy: 0.9868\n",
      "Epoch 13/20\n",
      "64/64 [==============================] - 9s 135ms/step - loss: 0.0395 - accuracy: 0.9842 - val_loss: 0.0164 - val_accuracy: 0.9956\n",
      "Epoch 14/20\n",
      "64/64 [==============================] - 10s 149ms/step - loss: 0.0366 - accuracy: 0.9838 - val_loss: 0.0505 - val_accuracy: 0.9868\n",
      "Epoch 15/20\n",
      "64/64 [==============================] - 9s 135ms/step - loss: 0.0308 - accuracy: 0.9889 - val_loss: 0.0349 - val_accuracy: 0.9912\n",
      "Epoch 16/20\n",
      "64/64 [==============================] - 9s 135ms/step - loss: 0.0366 - accuracy: 0.9887 - val_loss: 0.0136 - val_accuracy: 0.9956\n",
      "Epoch 17/20\n",
      "64/64 [==============================] - 8s 130ms/step - loss: 0.0245 - accuracy: 0.9933 - val_loss: 0.0355 - val_accuracy: 0.9912\n",
      "Epoch 18/20\n",
      "64/64 [==============================] - 9s 135ms/step - loss: 0.0440 - accuracy: 0.9858 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "64/64 [==============================] - 9s 141ms/step - loss: 0.0185 - accuracy: 0.9946 - val_loss: 0.0753 - val_accuracy: 0.9559\n",
      "Epoch 20/20\n",
      "64/64 [==============================] - 9s 138ms/step - loss: 0.0302 - accuracy: 0.9902 - val_loss: 0.0651 - val_accuracy: 0.9912\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs=20,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 31ms/step - loss: 0.2122 - accuracy: 0.9841\n",
      "\n",
      "accuracy: 98.41%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test) #Evaluating the model with the help of test datas\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cnnmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
